{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('small_vocab_en.txt','r')\n",
    "en = f.read()\n",
    "\n",
    "f = open('small_vocab_fr.txt','r')\n",
    "fr = f.read()\n",
    "\n",
    "en = en.split('\\n')\n",
    "fr  = fr.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n"
     ]
    }
   ],
   "source": [
    "print(en[0])\n",
    "print(fr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tk = Tokenizer(char_level = False)\n",
    "en_tk.fit_on_texts(en)\n",
    "\n",
    "fr_tk = Tokenizer(char_level = False)\n",
    "fr_tk.fit_on_texts(fr)\n",
    "\n",
    "en_enc = en_tk.texts_to_sequences(en)\n",
    "fr_enc = fr_tk.texts_to_sequences(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "French:  new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "Encoded English:  [17, 23, 1, 8, 67, 4, 39, 7, 3, 1, 55, 2, 44]\n",
      "Encoded French :  [35, 34, 1, 8, 67, 37, 11, 24, 6, 3, 1, 112, 2, 50]\n"
     ]
    }
   ],
   "source": [
    "print \"English: \",en[0]\n",
    "print \"French: \",fr[0]\n",
    "print \"Encoded English: \",en_enc[0]\n",
    "print \"Encoded French : \",fr_enc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_enc = pad_sequences(fr_enc,10)\n",
    "en_enc = pad_sequences(en_enc,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('English VocabSize: ', 199)\n",
      "('French  VocabSize: ', 345)\n"
     ]
    }
   ],
   "source": [
    "print(\"English VocabSize: \",len(en_tk.word_index))\n",
    "print(\"French  VocabSize: \",len(fr_tk.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_enc = np.reshape(en_enc, (137861,10,1))\n",
    "fr_enc = np.reshape(fr_enc, (137861,10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = (10,1)\n",
    "\n",
    "input_seq = Input(input_dim)\n",
    "rnn = GRU(64, return_sequences = True)(input_seq)\n",
    "logits = TimeDistributed(Dense(len(en_tk.word_index)+1))(rnn)\n",
    "model = Model(input_seq, Activation('softmax')(logits))\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam(1e-3), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# French to English Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda2/lib/python2.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "137861/137861 [==============================] - 26s 190us/step - loss: 3.8685 - accuracy: 0.1986\n",
      "Epoch 2/10\n",
      "137861/137861 [==============================] - 27s 198us/step - loss: 2.6834 - accuracy: 0.4078\n",
      "Epoch 3/10\n",
      "137861/137861 [==============================] - 27s 193us/step - loss: 2.1110 - accuracy: 0.4902\n",
      "Epoch 4/10\n",
      "137861/137861 [==============================] - 29s 208us/step - loss: 1.8057 - accuracy: 0.5371\n",
      "Epoch 5/10\n",
      "137861/137861 [==============================] - 26s 188us/step - loss: 1.6057 - accuracy: 0.5805\n",
      "Epoch 6/10\n",
      "137861/137861 [==============================] - 26s 189us/step - loss: 1.4715 - accuracy: 0.6023\n",
      "Epoch 7/10\n",
      "137861/137861 [==============================] - 26s 190us/step - loss: 1.3723 - accuracy: 0.6234\n",
      "Epoch 8/10\n",
      "137861/137861 [==============================] - 26s 186us/step - loss: 1.2929 - accuracy: 0.6447\n",
      "Epoch 9/10\n",
      "137861/137861 [==============================] - 28s 203us/step - loss: 1.2286 - accuracy: 0.6585\n",
      "Epoch 10/10\n",
      "137861/137861 [==============================] - 28s 201us/step - loss: 1.1743 - accuracy: 0.6711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xb2a0596d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(fr_enc, en_enc, batch_size=1024, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "\n",
      "French :  fruit préféré est l'orange mais mon préféré est le raisin\n",
      "Actual :  fruit is the orange but my favorite is the grape\n",
      "Pred   :  is favorite during orange but my least is the grape\n",
      "\n",
      "----------------------------------------------------------\n",
      "\n",
      "French :  relaxant en décembre mais il est généralement froid en juillet\n",
      "Actual :  relaxing during december but it is usually chilly in july\n",
      "Pred   :  dry during february but it is usually pleasant in september\n",
      "\n",
      "----------------------------------------------------------\n",
      "\n",
      "French :  occupé au printemps et il est jamais chaude en mars\n",
      "Actual :  busy during spring and it is never hot in march\n",
      "Pred   :  snowy during spring and it is never snowy in winter\n",
      "\n",
      "----------------------------------------------------------\n",
      "\n",
      "French :  aimé le citron mais mon moins aimé est le raisin\n",
      "Actual :  is the lemon but my least liked is the grape\n",
      "Pred   :  is the lemon but my least liked is the lemon\n",
      "\n",
      "----------------------------------------------------------\n",
      "\n",
      "French :  occupé en janvier et il est parfois chaud en novembre\n",
      "Actual :  busy during january and it is sometimes warm in november\n",
      "Pred   :  snowy during january and it is sometimes warm in april\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ind in range(5,10):\n",
    "    \n",
    "    pred = model.predict(fr_enc[ind:ind+1])[0]\n",
    "\n",
    "    pre = []\n",
    "    act = []\n",
    "    inp = []\n",
    "\n",
    "    for i in pred:\n",
    "        pre.append(en_tk.index_word[np.argmax(i)])\n",
    "\n",
    "    for i in range(10):\n",
    "        inp.append(fr_tk.index_word[fr_enc[ind:ind+1][0][i][0]])\n",
    "        \n",
    "    for i in range(10):\n",
    "        act.append(en_tk.index_word[en_enc[ind:ind+1][0][i][0]])\n",
    "\n",
    "    print '----------------------------------------------------------'\n",
    "    \n",
    "    print\n",
    "    print \"French : \",' '.join(inp)\n",
    "    print \"Actual : \",' '.join(act)\n",
    "    print \"Pred   : \",' '.join(pre)\n",
    "    print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
